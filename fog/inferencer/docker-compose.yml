version: '3'

services:
  local-inferencer:
    image: muhandre/fogverse:local-inferencer
    environment:
    - CONSUMER_SERVERS=localhost:9093
    - PRODUCER_SERVERS=localhost:9093
    - CONSUMER_TOPIC=input
    - PRODUCER_TOPIC=result
    - MODEL=yolov5n
    restart: always
    network_mode: host
    # deploy:
    #   resources:
    #     limits:
    #       cpus: '0.75'
    #       memory: 2800M
    #     reservations:
    #       devices:
    #         - capabilities: [gpu]